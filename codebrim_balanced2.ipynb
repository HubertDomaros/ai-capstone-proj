{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "yolo_dataset_path = ''\n",
    "if IN_COLAB:\n",
    "  print('Using Google Colab')\n",
    "  input_dataset_path = kagglehub.dataset_download('arct22/codebrim-balanced')\n",
    "  yolo_dataset_path = '/content/'\n",
    "  print(input_dataset_path)\n",
    "  print('Data source import complete.')\n",
    "  print(listdir(input_dataset_path))\n",
    "elif os.environ.get('KAGGLE_KERNEL_RUN_TYPE') == 'interactive':\n",
    "  print('Using Kaggle Kernel')\n",
    "  input_dataset_path = '/kaggle/input/codebrim-balanced'\n",
    "  print('Data source import complete.')\n",
    "  print(os.listdir(input_dataset_path))\n",
    "else:\n",
    "  print(f'Using Local Machine. Operating System: {sys.platform}')\n",
    "  input_dataset_path = join(os.getcwd(), r'kaggle\\input\\codebrim-balanced') if os.path.exists(join(os.getcwd(), r'kaggle\\input\\codebrim-balanced')) else ValueError\n",
    "  yolo_dataset_path = join(os.getcwd(), r'datasets\\codebrim-balanced')\n",
    "  os.makedirs(yolo_dataset_path, exist_ok=True)\n",
    "  print('Data source import complete.')\n",
    "  print(f'input dataset path: {join(os.getcwd(),input_dataset_path)} \\ncontents: ',listdir(input_dataset_path))\n",
    "  print(f'yolo dataset path: {join(os.getcwd(),yolo_dataset_path)}')\n",
    "\n",
    "input_train_images = join(input_dataset_path, 'train', 'defects')\n",
    "input_test_images = join(input_dataset_path, 'test', 'defects')\n",
    "input_val_images = join(input_dataset_path, 'val', 'defects')\n",
    "\n",
    "yolo_train_images = join(yolo_dataset_path, 'images', 'train')\n",
    "yolo_test_images = join(yolo_dataset_path, 'images', 'test')\n",
    "yolo_val_images = join(yolo_dataset_path, 'images', 'val')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if sys.platform == 'linux' or sys.platform == 'linux2':\n",
    "  !pip install -U albumentations\n",
    "  !pip install xmltodict\n",
    "  !pip install --extra-index-url https://pypi.nvidia.com --upgrade nvidia-dali-cuda120\n",
    "  !pip install ultralytics\n",
    "from ultralytics import settings\n",
    "print(settings)\n",
    "if IN_COLAB:\n",
    "\n",
    "  settings.update({\n",
    "      'runs_dir': '/content/runs',\n",
    "      'weights_dir': '/content/weights',\n",
    "      'datasets_dir': yolo_dataset_path\n",
    "      })\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from ultralytics import YOLO\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ],
   "id": "529820f3fa34a446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# @title\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "def pad_and_resize(target_width: int, target_height: int, input_path: str, output_path: str) -> None:\n",
    "  imgs = os.listdir(input_path)\n",
    "\n",
    "  os.makedirs(output_path, exist_ok=True)\n",
    "  for img_name in tqdm(imgs):\n",
    "      if not img_name.endswith(('.jpg', '.png')):\n",
    "          continue\n",
    "\n",
    "      img = cv2.imread(os.path.join(input_path, img_name))\n",
    "      shape = img.shape\n",
    "      height = shape[0]\n",
    "      width = shape[1]\n",
    "\n",
    "      pipeline = 0\n",
    "      if height > width:\n",
    "          pipeline = A.Compose([\n",
    "              A.PadIfNeeded(width, width),\n",
    "              A.Resize(640, 640)\n",
    "      ])\n",
    "      else:\n",
    "          pipeline = A.Compose([\n",
    "              A.PadIfNeeded(height, height),\n",
    "              A.Resize(640, 640)\n",
    "          ])\n",
    "\n",
    "      transformed = pipeline(image=img)\n",
    "      cv2.imwrite(os.path.join(output_path, img_name), transformed['image'])\n",
    "\n",
    "  print(f'{len(os.listdir(output_path))} images padded, resized to w:{target_width}, h:{target_height} and saved in dir {output_path}')"
   ],
   "id": "15791a3f0bb7d0ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for img_dir in ['train', 'test', 'val']:\n",
    "    match img_dir:\n",
    "        # case 'train':\n",
    "        #     pad_and_resize(640, 640, input_train_images, yolo_train_images)\n",
    "        #case 'test':\n",
    "            #pad_and_resize(640, 640, input_test_images, yolo_test_images)\n",
    "        case 'val':\n",
    "            pad_and_resize(640, 640, input_val_images, yolo_val_images)\n",
    "\n",
    "    # pad_and_resize(640, 640, join(input_dataset_path, img_dir, 'defects'), yolo_dataset_path)\n"
   ],
   "id": "c7a765492d988320",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import xmltodict\n",
    "\n",
    "xml = ''\n",
    "with open(os.path.join(input_dataset_path, 'metadata/defects.xml'), 'r') as file:\n",
    "    xml = file.read()\n",
    "\n",
    "defects_json = xmltodict.parse(xml)\n",
    "defects_json = defects_json.get('Annotation').get('Defect')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "defects_df = pd.DataFrame(defects_json)\n",
    "defects_df"
   ],
   "id": "41927c34f9bfe9f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "defect_labels_arr = pd.DataFrame(defects_json).to_numpy()\n",
    "defect_imgs ={\n",
    "    'train': os.listdir(yolo_train_images),\n",
    "    'test': os.listdir(yolo_test_images),\n",
    "    'val': os.listdir(yolo_val_images)\n",
    "}\n",
    "\n",
    "defect_labels_dict = {\n",
    "    'train': [],\n",
    "    'test': [],\n",
    "    'val': []\n",
    "    }\n",
    "\n",
    "for defect in defect_labels_arr:\n",
    "    if defect[0] in defect_imgs['train']:\n",
    "        defect_labels_dict['train'].append(defect.tolist())\n",
    "    elif defect[0] in defect_imgs['test']:\n",
    "        defect_labels_dict['test'].append(defect.tolist())\n",
    "    else:\n",
    "        defect_labels_dict['val'].append(defect.tolist())"
   ],
   "id": "2fff4b10829995e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(defect_imgs['val'])",
   "id": "6ce6c241a9e86a7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame(defect_labels_dict['train'])",
   "id": "675991726353fa23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_label_in_yolo_format(mhot_labels):\n",
    "    x_center = 0.5\n",
    "    y_center = 0.5\n",
    "\n",
    "    present_labels = []\n",
    "    i = 0\n",
    "    for val in mhot_labels:\n",
    "        if val.isdigit():\n",
    "            if int(val) == 1:\n",
    "                present_labels.append(i)\n",
    "            i += 1\n",
    "\n",
    "    out_list = []\n",
    "    for label in present_labels:\n",
    "        out_list.append(\" \".join(map(str, [label, 0.5, 0.5, 1, 1])))\n",
    "\n",
    "    return out_list\n",
    "\n",
    "yolo_labels_dir = join(yolo_dataset_path, 'labels')\n",
    "example_label_yolo = get_label_in_yolo_format(defect_labels_dict['train'][0])"
   ],
   "id": "29023930d3d2257f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d = []\n",
    "\n",
    "for label_dir in defect_labels_dict.keys():\n",
    "    defects = defect_labels_dict[label_dir]\n",
    "    os.makedirs(os.path.join(yolo_labels_dir, label_dir), exist_ok=True)\n",
    "    for row in defects:\n",
    "        filepath = os.path.join(yolo_labels_dir, label_dir, row[0].split('.')[0] + '.txt')\n",
    "        yolo_label = get_label_in_yolo_format(row)\n",
    "\n",
    "        with open(filepath, 'w') as file:\n",
    "            for label in yolo_label:\n",
    "                file.write(label + '\\n')\n",
    "        d.append([filepath, yolo_label])\n",
    "    #print(label_dir, defects)\n"
   ],
   "id": "e96bcba268f79b7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pd.DataFrame(d)",
   "id": "a8874bec75b84c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "results = model.train(data=os.path.joinon(os.getcwd(), 'yolo_balanced.yaml'), epochs=1, imgsz=640)"
   ],
   "id": "177f7ec067ec504c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
