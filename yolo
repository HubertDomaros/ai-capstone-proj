{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10319251,"sourceType":"datasetVersion","datasetId":6388851}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/working'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T01:32:58.565621Z","iopub.execute_input":"2025-01-09T01:32:58.565994Z","iopub.status.idle":"2025-01-09T01:32:58.569860Z","shell.execute_reply.started":"2025-01-09T01:32:58.565966Z","shell.execute_reply":"2025-01-09T01:32:58.568962Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"!pip install scikit-multilearn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nprint(os.getcwd())\n!git clone https://github.com/HubertDomaros/ai-capstone-proj.git --branch dev\nif os.getcwd() != '/kaggle/working/ai-capstone-proj':\n    os.chdir('/kaggle/working/ai-capstone-proj')\n    print(os.getcwd())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T01:33:06.113000Z","iopub.execute_input":"2025-01-09T01:33:06.113328Z","iopub.status.idle":"2025-01-09T01:33:06.241005Z","shell.execute_reply.started":"2025-01-09T01:33:06.113299Z","shell.execute_reply":"2025-01-09T01:33:06.239967Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/ai-capstone-proj\nfatal: destination path 'ai-capstone-proj' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import os\nfrom multiprocessing import Pool, cpu_count\n\nfrom src import annotation_extractor as an_ext\nfrom src import image_processing as improc\nfrom src import utils as u\nfrom src import constants as c\n\nimport pandas as pd\nimport numpy as np\nimport cv2\n\ndataset_path = r'/kaggle/input/codebrim-original/original_dataset'\nannotations_path = os.path.join(dataset_path, r'annotations')\nannotations_df = an_ext.xml_annotations_to_dataframe(annotations_path)\nfrom skmultilearn.model_selection import iterative_train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T01:33:25.101528Z","iopub.execute_input":"2025-01-09T01:33:25.101928Z","iopub.status.idle":"2025-01-09T01:33:27.508493Z","shell.execute_reply.started":"2025-01-09T01:33:25.101896Z","shell.execute_reply":"2025-01-09T01:33:27.507791Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"annotations_df.sort_values(by='img', inplace=True)\nannotations_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T01:35:02.584932Z","iopub.execute_input":"2025-01-09T01:35:02.585261Z","iopub.status.idle":"2025-01-09T01:35:02.607211Z","shell.execute_reply.started":"2025-01-09T01:35:02.585239Z","shell.execute_reply":"2025-01-09T01:35:02.606533Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                    img width height  xmin  ymin  xmax  ymax  Background  \\\n5198  image_0000005.jpg  1904   2856  1507   505  1904  2856           0   \n5197  image_0000005.jpg  1904   2856   661   472   992  1857           0   \n3489  image_0000021.jpg  1904   2856   253     8   335  2108           0   \n4903  image_0000028.jpg  1752   2632     1     1   907  1043           0   \n4904  image_0000028.jpg  1752   2632  1173     1  1747  1077           0   \n...                 ...   ...    ...   ...   ...   ...   ...         ...   \n4825  image_0001599.jpg  4608   3456  1921     1  3105   800           0   \n4826  image_0001599.jpg  4608   3456   226     1   647  2710           0   \n4820  image_0001599.jpg  4608   3456  2092   471  2416  1178           0   \n4827  image_0001599.jpg  4608   3456  1002  1097  2931  3456           0   \n4682  image_0001600.jpg  4608   3456     0     0  4608  3456           1   \n\n      Crack  Spallation  Efflorescence  ExposedBars  CorrosionStain  \n5198      0           0              1            0               1  \n5197      0           0              1            0               1  \n3489      0           0              1            0               0  \n4903      0           0              1            0               1  \n4904      0           0              1            0               0  \n...     ...         ...            ...          ...             ...  \n4825      0           1              0            1               1  \n4826      0           0              0            0               1  \n4820      0           0              0            0               1  \n4827      0           0              1            0               1  \n4682      0           0              0            0               0  \n\n[5261 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img</th>\n      <th>width</th>\n      <th>height</th>\n      <th>xmin</th>\n      <th>ymin</th>\n      <th>xmax</th>\n      <th>ymax</th>\n      <th>Background</th>\n      <th>Crack</th>\n      <th>Spallation</th>\n      <th>Efflorescence</th>\n      <th>ExposedBars</th>\n      <th>CorrosionStain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5198</th>\n      <td>image_0000005.jpg</td>\n      <td>1904</td>\n      <td>2856</td>\n      <td>1507</td>\n      <td>505</td>\n      <td>1904</td>\n      <td>2856</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5197</th>\n      <td>image_0000005.jpg</td>\n      <td>1904</td>\n      <td>2856</td>\n      <td>661</td>\n      <td>472</td>\n      <td>992</td>\n      <td>1857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3489</th>\n      <td>image_0000021.jpg</td>\n      <td>1904</td>\n      <td>2856</td>\n      <td>253</td>\n      <td>8</td>\n      <td>335</td>\n      <td>2108</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4903</th>\n      <td>image_0000028.jpg</td>\n      <td>1752</td>\n      <td>2632</td>\n      <td>1</td>\n      <td>1</td>\n      <td>907</td>\n      <td>1043</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4904</th>\n      <td>image_0000028.jpg</td>\n      <td>1752</td>\n      <td>2632</td>\n      <td>1173</td>\n      <td>1</td>\n      <td>1747</td>\n      <td>1077</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4825</th>\n      <td>image_0001599.jpg</td>\n      <td>4608</td>\n      <td>3456</td>\n      <td>1921</td>\n      <td>1</td>\n      <td>3105</td>\n      <td>800</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4826</th>\n      <td>image_0001599.jpg</td>\n      <td>4608</td>\n      <td>3456</td>\n      <td>226</td>\n      <td>1</td>\n      <td>647</td>\n      <td>2710</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4820</th>\n      <td>image_0001599.jpg</td>\n      <td>4608</td>\n      <td>3456</td>\n      <td>2092</td>\n      <td>471</td>\n      <td>2416</td>\n      <td>1178</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4827</th>\n      <td>image_0001599.jpg</td>\n      <td>4608</td>\n      <td>3456</td>\n      <td>1002</td>\n      <td>1097</td>\n      <td>2931</td>\n      <td>3456</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4682</th>\n      <td>image_0001600.jpg</td>\n      <td>4608</td>\n      <td>3456</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4608</td>\n      <td>3456</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5261 rows Ã— 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"os.listdir('/kaggle/working/ai-capstone-proj')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T01:35:28.362254Z","iopub.execute_input":"2025-01-09T01:35:28.362577Z","iopub.status.idle":"2025-01-09T01:35:28.368891Z","shell.execute_reply.started":"2025-01-09T01:35:28.362553Z","shell.execute_reply":"2025-01-09T01:35:28.367972Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"['ai-capstone-proj',\n 'brudnopis.ipynb',\n 'src',\n 'tests',\n 'train.py',\n 'pytorch_tests.ipynb',\n '.gitignore',\n '.git',\n 'examples',\n 'requirements.txt',\n 'debug_file.py',\n 'README.md']"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"def train_test_val_image_split(input_df: pd.DataFrame,\n                               test_size: float = 0.2,\n                               val_size: float = 0.1) -> dict[str, np.ndarray]:\n    \"\"\"\n    Splits the input DataFrame into training, testing, and validation sets\n    based on images. If there are multiple entries of the same image, it merges them by \n    maximum value of each label.\n\n    Parameters:\n    ----------\n    input_df : pd.DataFrame\n        A pandas DataFrame containing image file names, bounding box coordinates\n         in format (xmin, xmax, ymin, ymax) and their corresponding multi-hot encoded labels.\n\n    Returns:\n    -------\n    dict[str, ndarray]\n        A dictionary with keys 'train', 'test', and 'val',\n        each containing a NumPy array of image file names for the respective dataset.\n    \"\"\"\n    if input_df.empty:\n        raise ValueError('Input DataFrame is empty')\n\n    if not (0 < test_size < 1) or not (0 <= val_size < 1):\n        raise ValueError(\"test_size and val_size must be between 0 and 1.\")\n\n    if (test_size + val_size) >= 1:\n        raise ValueError(\"The sum of test_size and val_size must be less than 1.\")\n\n    df = input_df.drop(['xmin', 'xmax', 'ymin', 'ymax'], axis=1)\n    df = df.groupby('image', as_index=False).max()\n\n    X: np.ndarray = df['image'].to_numpy()\n    y: np.ndarray = df.drop(['image', 'width', 'height'], axis=1).to_numpy()\n\n    X_train, y_train, X_rem, y_rem = iterative_train_test_split(X, y, test_size=(test_size + val_size))\n\n    X_test, y_test, X_val, y_val = iterative_train_test_split(X_rem, y_rem,\n                                                     test_size=(val_size / (test_size + val_size)))\n\n    out_dict = {\n        'train': (X_train, y_train)\n        'test': (X_test, y_test),\n        'val': (X_val, y_val),\n    }\n\n    return out_dict\n\n\ndef dict_to_json(input_dict: dict[str, np.ndarray], out_filepath: str) -> None:\n    \"\"\"\n    Saves a dictionary to a JSON file.\n\n    Parameters:\n    ----------\n    input_dict : dict[str, np.ndarray]\n        The dictionary to save.\n    out_filepath : str\n        The path to the output JSON file.\n    \"\"\"\n    # Convert NumPy arrays to lists\n    serializable_dict = {key: value.tolist() for key, value in input_dict.items()}\n\n    with open(out_filepath, 'w') as file:\n        json.dump(serializable_dict, file, indent=4)\n\n\n\ndef put_splited_images_in_folders(json_filepath: str, input_dir: str, out_dir: str) -> None:\n    with open(json_filepath, 'r') as json_file:\n        json_obj: dict = json.load(json_file)\n        datasets = ['train', 'test', 'val']\n\n    for dataset_name in datasets:\n        dataset_dir = os.path.join(out_dir, dataset_name)\n        if os.path.exists(dataset_dir):\n            raise OSError(f'Cannot make directory, {dataset_dir} already exists')\n\n        os.makedirs(dataset_dir)\n        print(f\"Created directory {dataset_dir}\")\n\n        for img in json_obj[dataset_name]:\n            src = os.path.join(input_dir, img)\n            out = os.path.join(dataset_dir, img)\n\n            try:\n                raise_exeption_if_file_exists(out)\n            except FileExistsError:\n                print(f'File {img} in path {dataset_dir} already exists. Skipping copying operation')\n                continue\n\n            os.symlink(src, out)\n\n\ndef raise_exeption_if_file_exists(filepath: str):\n    if os.path.exists(filepath):\n        raise FileExistsError","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import albumentations as A","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"A.","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}