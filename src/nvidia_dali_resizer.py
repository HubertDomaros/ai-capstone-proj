#This file resizes images on gpu. Generated by ChatGPT and Claude Sonnet 3.5.

# Define paths
from sys import platform

def resize_with_dali():
    if platform == 'win32':
        print('This function is not runnable on Windows :/')
    import os
    import glob
    from nvidia.dali.pipeline import Pipeline
    import nvidia.dali.fn as fn
    import nvidia.dali.types as types
    import cv2
    import numpy as np

    # Define paths
    input_dir = "/kaggle/input/codebrim-original/original_dataset/images"
    output_dir = "/kaggle/working/resized"
    os.makedirs(output_dir, exist_ok=True)
    image_files = sorted([f for f in os.listdir(input_dir) if f.endswith('.jpg')])
    total_images = len(image_files)

    # Debug: Print directory contents and verify paths
    print(f"Input directory exists: {os.path.exists(input_dir)}")
    print(f"Is directory: {os.path.isdir(input_dir)}")
    print(f"\nFirst 5 files in directory:")
    files = sorted(os.listdir(input_dir))
    print(files[:5])
    print(f"\nTotal files: {len(files)}")

    # Debug: Check actual full paths of some files
    print("\nFull paths of first few files:")
    for f in files[:3]:
        full_path = os.path.join(input_dir, f)
        print(f"{full_path} (exists: {os.path.exists(full_path)})")

    # Create a temporary file list for DALI
    file_list_path = "temp_file_list.txt"
    with open(file_list_path, 'w') as f:
        for file_name in files:
            if file_name.endswith('.jpg'):
                full_path = os.path.join(input_dir, file_name)
                f.write(f"{full_path} 0\n")  # Adding dummy label 0

    print(f"\nCreated file list at {file_list_path}")
    print("First few lines of file list:")
    with open(file_list_path, 'r') as f:
        print(f.read().splitlines()[:3])

    class ResizePipeline(Pipeline):
        def __init__(self, batch_size, num_threads, device_id, resize_width, resize_height):
            super(ResizePipeline, self).__init__(batch_size, num_threads, device_id)
            self.resize_width = resize_width
            self.resize_height = resize_height

        def define_graph(self):
            # Use file_list instead of file_root
            inputs = fn.readers.file(
                file_list=file_list_path,
                name="Reader"
            )

            jpegs, _ = inputs  # Unpack images and labels

            decoded = fn.decoders.image(
                jpegs,
                device="mixed",
                output_type=types.RGB
            )

            resized = fn.resize(
                decoded,
                device="gpu",
                resize_x=self.resize_width,
                resize_y=self.resize_height,
                interp_type=types.INTERP_LINEAR
            )

            return resized

    print("\nTrying to create and build pipeline...")

    pipeline = ResizePipeline(
        batch_size=32,
        num_threads=4,
        device_id=0,
        resize_width=224,
        resize_height=224
    )

    pipeline.build()
    print("Pipeline built successfully!")

    # Process all images
    processed_count = 0
    batch_idx = 0
    print("\nProcessing and saving images:")

    while processed_count < total_images:
        # Run the pipeline
        outputs = pipeline.run()

        # Get the batch data
        resized_images = outputs[0].as_cpu().as_array()

        # Process each image in the batch
        for idx, img in enumerate(resized_images):
            if processed_count >= total_images:
                break

            # Get filename from our sorted list
            orig_filename = image_files[batch_idx * pipeline.max_batch_size + idx]
            output_path = os.path.join(output_dir, orig_filename)

            # Convert to uint8 and BGR (for cv2.imwrite)
            img_bgr = cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_RGB2BGR)

            # Save the image
            cv2.imwrite(output_path, img_bgr)
            processed_count += 1

            # Print progress
            if processed_count % 100 == 0:
                print(f"Processed {processed_count}/{total_images} images")

        batch_idx += 1

    print(f"\nAll done! {processed_count} images have been resized and saved to {output_dir}")

    # Print some statistics about the saved files
    saved_files = os.listdir(output_dir)
    print(f"\nVerification:")
    print(f"Number of files in output directory: {len(saved_files)}")
    print(f"Sample of saved files: {saved_files[:5]}")