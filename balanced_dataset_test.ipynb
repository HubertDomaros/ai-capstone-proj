{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T23:44:04.682986Z",
     "start_time": "2025-01-14T23:43:59.858388Z"
    }
   },
   "source": [
    "import imagesize\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = r'D:\\0-Code\\PG\\2_sem\\0_Dyplom\\ai-capstone-proj\\kaggle\\input\\CODEBRIM-balanced\\train\\defects'\n",
    "files = os.listdir(path)\n",
    "\n",
    "shape_dict = {\n",
    "    'img': [],\n",
    "    'width': [],\n",
    "    'height': []\n",
    "}\n",
    "for file in files:\n",
    "    if file.endswith('.png') or file.endswith('.jpg') or file.endswith('.jpeg'):\n",
    "        shape = imagesize.get(os.path.join(path, file))\n",
    "        shape_dict['img'].append(os.path.join(file))\n",
    "        shape_dict['width'].append(shape[0])\n",
    "        shape_dict['height'].append(shape[1])\n",
    "\n",
    "df = pd.DataFrame(shape_dict)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                        img  width  height\n",
       "0            image_0000005_crop_0000001.png    331    1385\n",
       "1     image_0000005_crop_0000001_copy00.png    331    1385\n",
       "2     image_0000005_crop_0000001_copy01.png    331    1385\n",
       "3     image_0000005_crop_0000001_copy02.png    331    1385\n",
       "4            image_0000005_crop_0000002.png    397    2351\n",
       "...                                     ...    ...     ...\n",
       "7019         image_0001599_crop_0000007.png    421    2709\n",
       "7020         image_0001599_crop_0000008.png   1929    2359\n",
       "7021  image_0001599_crop_0000008_copy00.png   1929    2359\n",
       "7022  image_0001599_crop_0000008_copy01.png   1929    2359\n",
       "7023  image_0001599_crop_0000008_copy02.png   1929    2359\n",
       "\n",
       "[7024 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_0000005_crop_0000001.png</td>\n",
       "      <td>331</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_0000005_crop_0000001_copy00.png</td>\n",
       "      <td>331</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_0000005_crop_0000001_copy01.png</td>\n",
       "      <td>331</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_0000005_crop_0000001_copy02.png</td>\n",
       "      <td>331</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_0000005_crop_0000002.png</td>\n",
       "      <td>397</td>\n",
       "      <td>2351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>image_0001599_crop_0000007.png</td>\n",
       "      <td>421</td>\n",
       "      <td>2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>image_0001599_crop_0000008.png</td>\n",
       "      <td>1929</td>\n",
       "      <td>2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>image_0001599_crop_0000008_copy00.png</td>\n",
       "      <td>1929</td>\n",
       "      <td>2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>image_0001599_crop_0000008_copy01.png</td>\n",
       "      <td>1929</td>\n",
       "      <td>2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>image_0001599_crop_0000008_copy02.png</td>\n",
       "      <td>1929</td>\n",
       "      <td>2359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7024 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T23:44:04.706531Z",
     "start_time": "2025-01-14T23:44:04.699031Z"
    }
   },
   "cell_type": "code",
   "source": "df[df['height'] == df['height'].max()]",
   "id": "7444ab8f5ff7ee8c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                       img  width  height\n",
       "145         image_0000199_crop_0000002.png    314    3999\n",
       "150         image_0000201_crop_0000001.png   3223    3999\n",
       "183         image_0000219_crop_0000001.png   1947    3999\n",
       "184  image_0000219_crop_0000001_copy00.png   1947    3999\n",
       "225         image_0000259_crop_0000001.png   1646    3999\n",
       "491         image_0000368_crop_0000001.png   2747    3999\n",
       "492  image_0000368_crop_0000001_copy00.png   2747    3999\n",
       "493  image_0000368_crop_0000001_copy01.png   2747    3999\n",
       "494  image_0000368_crop_0000001_copy02.png   2747    3999"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>image_0000199_crop_0000002.png</td>\n",
       "      <td>314</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>image_0000201_crop_0000001.png</td>\n",
       "      <td>3223</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>image_0000219_crop_0000001.png</td>\n",
       "      <td>1947</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>image_0000219_crop_0000001_copy00.png</td>\n",
       "      <td>1947</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>image_0000259_crop_0000001.png</td>\n",
       "      <td>1646</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>image_0000368_crop_0000001.png</td>\n",
       "      <td>2747</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>image_0000368_crop_0000001_copy00.png</td>\n",
       "      <td>2747</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>image_0000368_crop_0000001_copy01.png</td>\n",
       "      <td>2747</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>image_0000368_crop_0000001_copy02.png</td>\n",
       "      <td>2747</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-14T23:54:52.665520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def pad_to_square(image: torch.Tensor, pad_value: float = 0.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Pad the smaller dimension of an image to make it square.\n",
    "\n",
    "    Args:\n",
    "        image (torch.Tensor): Input image tensor of shape (C, H, W) or (B, C, H, W)\n",
    "        pad_value (float): Value to use for padding (default: 0.0)\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Padded square image with height = width\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        h, w, c = image.shape\n",
    "        batch_mode = False\n",
    "    elif len(image.shape) == 4:\n",
    "        b, c, h, w = image.shape\n",
    "        batch_mode = True\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 3D or 4D tensor, got shape {image.shape}\")\n",
    "\n",
    "    if h == w:\n",
    "        return image\n",
    "\n",
    "    diff = abs(h - w)\n",
    "    pad_1 = diff // 2\n",
    "    pad_2 = diff - pad_1\n",
    "\n",
    "    # Determine which dimension to pad\n",
    "    if h < w:\n",
    "        padding = (0, 0, pad_1, pad_2)  # left, right, top, bottom\n",
    "    else:\n",
    "        padding = (pad_1, pad_2, 0, 0)  # left, right, top, bottom\n",
    "\n",
    "    if batch_mode:\n",
    "        return F.pad(image, padding, mode='constant', value=pad_value)\n",
    "    else:\n",
    "        return F.pad(image.unsqueeze(0), padding, mode='constant', value=pad_value).squeeze(0)\n",
    "\n",
    "def pad_to_square_numpy(image: np.ndarray, pad_value: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Pad the smaller dimension of an image to make it square (NumPy version).\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Input image array of shape (H, W, C) or (H, W)\n",
    "        pad_value (int): Value to use for padding (default: 0)\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Padded square image with height = width\n",
    "    \"\"\"\n",
    "    if len(image.shape) == 3:\n",
    "        h, w, c = image.shape\n",
    "    elif len(image.shape) == 2:\n",
    "        h, w = image.shape\n",
    "        c = None\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 2D or 3D array, got shape {image.shape}\")\n",
    "\n",
    "    if h == w:\n",
    "        return image\n",
    "\n",
    "    diff = abs(h - w)\n",
    "    pad_1 = diff // 2\n",
    "    pad_2 = diff - pad_1\n",
    "\n",
    "    # Create padding configuration\n",
    "    if h < w:\n",
    "        if c is None:\n",
    "            padding = ((pad_1, pad_2), (0, 0))\n",
    "        else:\n",
    "            padding = ((pad_1, pad_2), (0, 0), (0, 0))\n",
    "    else:\n",
    "        if c is None:\n",
    "            padding = ((0, 0), (pad_1, pad_2))\n",
    "        else:\n",
    "            padding = ((0, 0), (pad_1, pad_2), (0, 0))\n",
    "\n",
    "    return np.pad(image, padding, mode='constant', constant_values=pad_value)\n",
    "\n",
    "def cv2_to_tensor(img,\n",
    "                 normalize=True,\n",
    "                 to_float=True,\n",
    "                 channel_first=True,\n",
    "                 device='cpu') -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a CV2 image to a PyTorch tensor.\n",
    "\n",
    "    Args:\n",
    "        img: CV2 image (numpy array) in BGR format\n",
    "        normalize: If True, normalize pixel values to [0, 1]\n",
    "        to_float: If True, convert to float32\n",
    "        channel_first: If True, change to (C, H, W) format\n",
    "        device: Target device for the tensor\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Processed image tensor\n",
    "    \"\"\"\n",
    "    # Handle both RGB and grayscale images\n",
    "    if len(img.shape) == 2:\n",
    "        # Add channel dimension for grayscale images\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    if img.shape[2] == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert to float and normalize if requested\n",
    "    if to_float:\n",
    "        img = img.astype(np.float32)\n",
    "        if normalize:\n",
    "            img = img / 255.0\n",
    "\n",
    "    # Convert to tensor\n",
    "    tensor = torch.from_numpy(img)\n",
    "\n",
    "    # Rearrange dimensions from (H, W, C) to (C, H, W) if requested\n",
    "    if channel_first:\n",
    "        tensor = tensor.permute(2, 0, 1)\n",
    "\n",
    "    return tensor.to(device)\n",
    "\n",
    "# NumPy example\n",
    "# Create a sample 200x100x3 array\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch_img = cv2.imread(os.path.join(path, 'image_0000199_crop_0000002.png'))\n",
    "torch_img = cv2.cvtColor(torch_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(torch_img.shape)\n",
    "torch_img = torch.from_numpy(torch_img)\n",
    "print(torch_img.shape)\n",
    "padded_torch_img = pad_to_square(torch_img)\n",
    "print(padded_torch_img.shape)\n",
    "plt.imshow(padded_torch_img)\n",
    "\n",
    "# numpy_img = cv2.imread(os.path.join(path, 'image_0000199_crop_0000002.png'))\n",
    "# padded_numpy = pad_to_square_numpy(numpy_img)\n",
    "# print(f\"Original numpy shape: {numpy_img.shape}\")\n",
    "# print(f\"Padded numpy shape: {padded_numpy.shape}\")\n",
    "#\n",
    "# plt.imshow(padded_numpy)"
   ],
   "id": "738ae031142314fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 314, 3)\n",
      "torch.Size([3999, 314, 3])\n",
      "torch.Size([3999, 314, 3688])\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "os.makedirs('images', exist_ok=True)",
   "id": "7a4c8adef9fd7bbc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
